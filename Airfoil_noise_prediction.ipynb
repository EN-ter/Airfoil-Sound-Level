{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "7ade9c37d49d8d8ca6fc6e9e3c3b8b99b1549067e622440dcb8959d88a3508fd"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Project Build an ML Pipeline for Airfoil noise prediction\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n\nIn this 4 part assignment you will:\n\n- Part 1 Perform ETL activity\n  - Load a csv dataset\n  - Remove duplicates if any\n  - Drop rows with null values if any\n  - Make transformations\n  - Store the cleaned data in parquet format\n- Part 2 Create a  Machine Learning Pipeline\n  - Create a machine learning pipeline for prediction\n- Part 3 Evaluate the Model\n  - Evaluate the model using relevant metrics\n- Part 4 Persist the Model \n  - Save the model for future production use\n  - Load and verify the stored model\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Datasets\n\n - The original dataset can be found here NASA airfoil self noise dataset. https://archive.ics.uci.edu/dataset/291/airfoil+self+noise\n \n - This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Diagram of an airfoil. - For informational purpose\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "![Airfoil with flow](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_with_flow.png)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Diagram showing the Angle of attack. - For informational purpose\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "![Airfoil angle of attack](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_angle_of_attack.jpg)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Installing Required Libraries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install pyspark==3.1.2 -q\n!pip install findspark -q",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Importing Required Libraries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# You can also use this section to suppress warnings generated by your code:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')\n\n# FindSpark simplifies the process of using Apache Spark with Python\n\nimport findspark\nfindspark.init()",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "## Part 1 - Perform ETL activity\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Task 1 - Import required libraries\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.pipeline import PipelineModel\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.evaluation import RegressionEvaluator",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2 - Create a spark session\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "spark = SparkSession.builder.appName(\"Airfoil Noise Prediction\").getOrCreate()",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "25/08/21 20:18:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n,Setting default log level to \"WARN\".\n,To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3 - Load the csv file into a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "--2025-08-21 20:19:19--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n,Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n,Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n,HTTP request sent, awaiting response... 200 OK\n,Length: 60682 (59K) [text/csv]\n,Saving to: ‘NASA_airfoil_noise_raw.csv.2’\n,\n,NASA_airfoil_noise_ 100%[===================>]  59.26K  --.-KB/s    in 0.001s  \n,\n,2025-08-21 20:19:19 (53.0 MB/s) - ‘NASA_airfoil_noise_raw.csv.2’ saved [60682/60682]\n,\n"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "airfoil_df = spark.read.csv(\"NASA_airfoil_noise_raw.csv\", header=True, inferSchema=True)",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4 - Print top 5 rows of the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df.show(5)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+---------+-------------+-----------+------------------+-----------------------+----------+\n,|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n,+---------+-------------+-----------+------------------+-----------------------+----------+\n,|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n,|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n,|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n,|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n,|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n,+---------+-------------+-----------+------------------+-----------------------+----------+\n,only showing top 5 rows\n,\n"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "### Task 6 - Print the total number of rows in the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rowcount1 = airfoil_df.count()\nprint(rowcount1)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1522\n"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "### Task 7 - Drop all the duplicate rows from the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df = airfoil_df.dropDuplicates()",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "### Task 8 - Print the total number of rows in the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rowcount2 = airfoil_df.count()\nprint(rowcount2)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 6:=====================================================> (195 + 5) / 200]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1503\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "### Task 9 - Drop all the rows that contain null values from the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df = airfoil_df.dropna()\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### Task 10 - Print the total number of rows in the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#your code goes here\n\nrowcount3 = airfoil_df.count()\nprint(rowcount3)\n",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 9:=====================================================> (194 + 6) / 200]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1499\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "### Task 11 - Rename the column \"SoundLevel\" to \"SoundLevelDecibels\"\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df = airfoil_df.withColumnRenamed(\"SoundLevel\",\"SoundLevelDecibels\")\n\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "### Task 12 - Save the dataframe in parquet format, name the file as \"NASA_airfoil_noise_cleaned.parquet\"\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df.write.mode(\"overwrite\").parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n\nairfoil_df.show(5)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 14:>                                                       (0 + 8) / 200]25/08/21 20:21:37 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n,Scaling row group sizes to 96.54% for 7 writers\n,25/08/21 20:21:37 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n,Scaling row group sizes to 84.47% for 8 writers\n,25/08/21 20:21:38 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n,Scaling row group sizes to 96.54% for 7 writers\n,                                                                                \r"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+---------+-------------+-----------+------------------+-----------------------+------------------+\n,|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevelDecibels|\n,+---------+-------------+-----------+------------------+-----------------------+------------------+\n,|     4000|          3.0|     0.3048|              31.7|             0.00529514|           115.608|\n,|     3150|          2.0|     0.2286|              31.7|             0.00372371|           121.527|\n,|     2000|          7.3|     0.2286|              31.7|              0.0132672|           115.309|\n,|     2000|          5.4|     0.1524|              71.3|             0.00401199|           131.111|\n,|      500|          9.9|     0.1524|              71.3|              0.0193001|           131.279|\n,+---------+-------------+-----------+------------------+-----------------------+------------------+\n,only showing top 5 rows\n,\n"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 1 - Evaluation\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Part 1 - Evaluation\")\n\nprint(\"Total rows = \", rowcount1)\nprint(\"Total rows after dropping duplicate rows = \", rowcount2)\nprint(\"Total rows after dropping duplicate rows and rows with null values = \", rowcount3)\nprint(\"New column name = \", airfoil_df.columns[-1])\n\nimport os\n\nprint(\"NASA_airfoil_noise_cleaned.parquet exists :\", os.path.isdir(\"NASA_airfoil_noise_cleaned.parquet\"))",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Part 1 - Evaluation\n,Total rows =  1522\n,Total rows after dropping duplicate rows =  1503\n,Total rows after dropping duplicate rows and rows with null values =  1499\n,New column name =  SoundLevelDecibels\n,NASA_airfoil_noise_cleaned.parquet exists : True\n"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "## Part - 2 Create a  Machine Learning Pipeline\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Task 1 - Load data from \"NASA_airfoil_noise_cleaned.parquet\" into a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "airfoil_df = spark.read.parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2 - Print the total number of rows in the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rowcount4 = airfoil_df.count()\nprint(rowcount4)\n\n",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 18:>                                                         (0 + 8) / 8]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1499\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3 - Define the VectorAssembler pipeline stage\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "assembler = VectorAssembler(inputCols=['Frequency','AngleOfAttack','ChordLength','FreeStreamVelocity','SuctionSideDisplacement'], outputCol=\"features\")\n\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4 - Define the StandardScaler pipeline stage\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "### Task 5 - Define the Model creation pipeline stage\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SoundLevelDecibels\")\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "### Task 6 - Build the pipeline\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "### Task 7 - Split the data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Split the data into training and testing sets with 70:30 split.\n# set the value of seed to 42\n\n(trainingData, testingData) = airfoil_df.randomSplit([0.7, 0.3], seed=42)",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "### Task 8 - Fit the pipeline\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipelineModel = pipeline.fit(trainingData)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "25/08/21 20:25:02 WARN util.Instrumentation: [9d3ce0ed] regParam is zero, which might cause numerical instability and overfitting.\n,[Stage 23:>                                                         (0 + 8) / 8]25/08/21 20:25:05 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n,25/08/21 20:25:05 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n,25/08/21 20:25:05 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n,25/08/21 20:25:05 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n,                                                                                \r"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 2 - Evaluation\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Part 2 - Evaluation\")\nprint(\"Total rows = \", rowcount4)\nps = [str(x).split(\"_\")[0] for x in pipeline.getStages()]\n\nprint(\"Pipeline Stage 1 = \", ps[0])\nprint(\"Pipeline Stage 2 = \", ps[1])\nprint(\"Pipeline Stage 3 = \", ps[2])\n\nprint(\"Label column = \", lr.getLabelCol())",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Part 2 - Evaluation\n,Total rows =  1499\n,Pipeline Stage 1 =  VectorAssembler\n,Pipeline Stage 2 =  StandardScaler\n,Pipeline Stage 3 =  LinearRegression\n,Label column =  SoundLevelDecibels\n"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "## Part 3 - Evaluate the Model\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Task 1 - Predict using the model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions on testing data\npredictions = pipelineModel.transform(testingData)",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2 - Print the MSE\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mse\")\nmse = evaluator.evaluate(predictions)\nprint(mse)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 30:=============================>                            (4 + 4) / 8]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "22.593754071348812\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3 - Print the MAE\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mae\")\nmae = evaluator.evaluate(predictions)\nprint(mae)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 32:>                                                         (0 + 8) / 8]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "3.7336902294631287\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4 - Print the R-Squared(R2)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"r2\")\nr2 = evaluator.evaluate(predictions)\nprint(r2)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 34:>                                                         (0 + 8) / 8]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0.5426016508689058\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 3 - Evaluation\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Part 3 - Evaluation\")\n\nprint(\"Mean Squared Error = \", round(mse,2))\nprint(\"Mean Absolute Error = \", round(mae,2))\nprint(\"R Squared = \", round(r2,2))\n\nlrModel = pipelineModel.stages[-1]\n\nprint(\"Intercept = \", round(lrModel.intercept,2))",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Part 3 - Evaluation\n,Mean Squared Error =  22.59\n,Mean Absolute Error =  3.73\n,R Squared =  0.54\n,Intercept =  132.6\n"
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "## Part 4 - Persist the Model\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Task 1 - Save the model to the path \"Final_Project\"\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Save the pipeline model as \"Final_Project\"\npipelineModel.write().save(\"Final_Project\")",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2 - Load the model from the path \"Final_Project\"\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load the pipeline model you have created in the previous step\nloadedPipelineModel = PipelineModel.load(\"Final_Project\")",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3 - Make predictions using the loaded model on the testdata\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Use the loaded pipeline model and make predictions using testingData\npredictions = loadedPipelineModel.transform(testingData)",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4 - Show the predictions\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#show top 5 rows from the predections dataframe. Display only the label column and predictions\npredictions.select(\"SoundLevelDecibels\",\"prediction\").show(5)",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Stage 56:>                                                         (0 + 1) / 1]"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+------------------+------------------+\n,|SoundLevelDecibels|        prediction|\n,+------------------+------------------+\n,|           127.315|123.64344009624753|\n,|           119.975|123.48695788614877|\n,|           121.783|124.38983849684254|\n,|           127.224|121.44706993294302|\n,|           122.229|125.68312652454188|\n,+------------------+------------------+\n,only showing top 5 rows\n,\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "                                                                                \r"
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 4 - Evaluation\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Part 4 - Evaluation\")\n\nloadedmodel = loadedPipelineModel.stages[-1]\ntotalstages = len(loadedPipelineModel.stages)\ninputcolumns = loadedPipelineModel.stages[0].getInputCols()\n\nprint(\"Number of stages in the pipeline = \", totalstages)\nfor i,j in zip(inputcolumns, loadedmodel.coefficients):\n    print(f\"Coefficient for {i} is {round(j,4)}\")",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Part 4 - Evaluation\n,Number of stages in the pipeline =  3\n,Coefficient for Frequency is -3.9728\n,Coefficient for AngleOfAttack is -2.4775\n,Coefficient for ChordLength is -3.3818\n,Coefficient for FreeStreamVelocity is 1.5789\n,Coefficient for SuctionSideDisplacement is -1.6465\n"
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": "spark.stop()",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": "<!--\n## Change Log\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--\n|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-05-26|0.1|Ramesh Sannareddy|Initial Version Created|\n-->\n",
      "metadata": {}
    }
  ]
}